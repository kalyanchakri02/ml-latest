{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJGbtC5qIyXDZLLrDiBY4L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalyanchakri02/ml-latest/blob/main/feature_training_catboost_gpu_repair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fJUk7TlIgGr",
        "outputId": "0e8058df-d5e8-44ea-cfe9-2b9a887201fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    balanced_accuracy_score,\n",
        "    f1_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =============================================================================\n",
        "# Reproducibility & dataset sizing\n",
        "# =============================================================================\n",
        "np.random.seed(42)\n",
        "n_samples = 60_000  # Reduced for faster notebook execution (increase for stronger stats)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: Generate a *latent* fault domain (hidden ground truth cause)\n",
        "# -----------------------------------------------------------------------------\n",
        "# This is NOT given to the model; it is used only to synthesize realistic signals.\n",
        "# =============================================================================\n",
        "fault_domains = np.random.choice(\n",
        "    [\"healthy\", \"software\", \"signal\", \"thermal\", \"silicon\"],\n",
        "    size=n_samples,\n",
        "    p=[0.70, 0.12, 0.10, 0.06, 0.02]  # class imbalance similar to real fleets\n",
        ")\n",
        "\n",
        "# GPU SKU / model is an observed categorical attribute\n",
        "gpu_model = np.random.choice(\n",
        "    [\"H100\", \"A100\", \"V100\", \"H200\", \"GB200\"],\n",
        "    n_samples,\n",
        "    p=[0.30, 0.25, 0.20, 0.15, 0.10]\n",
        ")\n",
        "\n",
        "# Whether the GPU uses active cooling (fan on card) vs server/chassis fans\n",
        "# Most data center GPUs are passive (fan is on chassis), hence p=[0.92, 0.08].\n",
        "is_active_cooling = np.random.choice([0, 1], n_samples, p=[0.92, 0.08])\n",
        "\n",
        "def normal_by_domain(dom, means, stds):\n",
        "    \"\"\"\n",
        "    Draw a normal-distributed feature whose mean/std depend on fault domain.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dom : array[str]\n",
        "        Per-sample domain label (latent).\n",
        "    means, stds : dict[str, float]\n",
        "        Mean and std per domain.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Feature values sampled per domain.\n",
        "    \"\"\"\n",
        "    mu = np.vectorize(means.get)(dom)\n",
        "    sd = np.vectorize(stds.get)(dom)\n",
        "    return np.random.normal(mu, sd, size=len(dom))\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: Synthesize observable telemetry/log signals\n",
        "# -----------------------------------------------------------------------------\n",
        "# Each signal is correlated with the latent fault domain to create learnable\n",
        "# patterns, but still includes overlap/noise to avoid \"perfect\" separability.\n",
        "# =============================================================================\n",
        "\n",
        "# GPU temperature (thermal domain is hottest; silicon tends to run hotter too)\n",
        "temp_c = normal_by_domain(\n",
        "    fault_domains,\n",
        "    means={\"healthy\": 70, \"software\": 72, \"signal\": 73, \"thermal\": 95, \"silicon\": 85},\n",
        "    stds={\"healthy\": 10, \"software\": 12, \"signal\": 12, \"thermal\": 6, \"silicon\": 10},\n",
        ")\n",
        "temp_c = np.clip(temp_c, 20, 110)  # enforce physically plausible bounds\n",
        "\n",
        "# Fan RPM (thermal tends to push fans high; other domains are more normal)\n",
        "fan_rpm = normal_by_domain(\n",
        "    fault_domains,\n",
        "    means={\"healthy\": 2500, \"software\": 2600, \"signal\": 2550, \"thermal\": 4200, \"silicon\": 2600},\n",
        "    stds={\"healthy\": 700, \"software\": 800, \"signal\": 800, \"thermal\": 600, \"silicon\": 800},\n",
        ")\n",
        "fan_rpm = np.clip(fan_rpm, 0, 6000)\n",
        "\n",
        "# Voltage (silicon/power-related issues show more droop and variance)\n",
        "voltage = normal_by_domain(\n",
        "    fault_domains,\n",
        "    means={\"healthy\": 1.20, \"software\": 1.20, \"signal\": 1.19, \"thermal\": 1.18, \"silicon\": 1.15},\n",
        "    stds={\"healthy\": 0.06, \"software\": 0.06, \"signal\": 0.07, \"thermal\": 0.08, \"silicon\": 0.10},\n",
        ")\n",
        "voltage = np.clip(voltage, 0.8, 1.4)\n",
        "\n",
        "# Retimer errors (signal integrity issues dominate; others have low background noise)\n",
        "retimer_errors = np.random.poisson(\n",
        "    lam=np.where(\n",
        "        fault_domains == \"signal\", 6.0,\n",
        "        np.where(\n",
        "            fault_domains == \"thermal\", 0.6,\n",
        "            np.where(\n",
        "                fault_domains == \"software\", 0.4,\n",
        "                np.where(fault_domains == \"silicon\", 1.0, 0.2)\n",
        "            )\n",
        "        )\n",
        "    ),\n",
        "    size=n_samples\n",
        ")\n",
        "\n",
        "# PCIe link width degradation is most common in signal/silicon domains\n",
        "pcie_width = np.where(\n",
        "    fault_domains == \"signal\",\n",
        "    np.random.choice([16, 8, 4, 1], n_samples, p=[0.50, 0.30, 0.15, 0.05]),\n",
        "    np.where(\n",
        "        fault_domains == \"silicon\",\n",
        "        np.random.choice([16, 8, 4, 1], n_samples, p=[0.40, 0.25, 0.20, 0.15]),\n",
        "        np.random.choice([16, 8, 4, 1], n_samples, p=[0.94, 0.03, 0.02, 0.01])\n",
        "    )\n",
        ").astype(int)\n",
        "\n",
        "# PCIe generation degradation pattern (similar story: signal/silicon show worse negotiation)\n",
        "pcie_gen = np.where(\n",
        "    fault_domains == \"signal\",\n",
        "    np.random.choice([5, 4, 3, 2, 1], n_samples, p=[0.60, 0.20, 0.15, 0.03, 0.02]),\n",
        "    np.where(\n",
        "        fault_domains == \"silicon\",\n",
        "        np.random.choice([5, 4, 3, 2, 1], n_samples, p=[0.55, 0.15, 0.15, 0.10, 0.05]),\n",
        "        np.random.choice([5, 4, 3, 2, 1], n_samples, p=[0.88, 0.06, 0.03, 0.02, 0.01])\n",
        "    )\n",
        ").astype(int)\n",
        "\n",
        "# XID codes represent driver/firmware/hardware fault signatures\n",
        "xid_code = np.where(\n",
        "    fault_domains == \"software\",\n",
        "    np.random.choice([\"XID_31\", \"XID_43\", \"XID_61\", \"NONE\"], n_samples, p=[0.35, 0.30, 0.25, 0.10]),\n",
        "    np.where(\n",
        "        fault_domains == \"signal\",\n",
        "        np.random.choice([\"XID_79\", \"NONE\", \"XID_43\"], n_samples, p=[0.45, 0.45, 0.10]),\n",
        "        np.where(\n",
        "            fault_domains == \"silicon\",\n",
        "            np.random.choice([\"XID_79\", \"NONE\", \"XID_61\"], n_samples, p=[0.55, 0.25, 0.20]),\n",
        "            np.random.choice([\"NONE\", \"XID_31\", \"XID_43\", \"XID_61\", \"XID_79\"], n_samples,\n",
        "                             p=[0.92, 0.03, 0.02, 0.02, 0.01])\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "# Aggregate error counts in a 24h window (silicon dominates; healthy is low)\n",
        "error_count_24h = np.random.poisson(\n",
        "    lam=np.where(\n",
        "        fault_domains == \"silicon\", 4.5,\n",
        "        np.where(\n",
        "            fault_domains == \"thermal\", 1.2,\n",
        "            np.where(\n",
        "                fault_domains == \"signal\", 1.0,\n",
        "                np.where(fault_domains == \"software\", 0.8, 0.3)\n",
        "            )\n",
        "        )\n",
        "    ),\n",
        "    size=n_samples\n",
        ")\n",
        "\n",
        "# \"Unfixable\" ECC errors: rare but strongly associated with silicon failures\n",
        "unfixable_ecc_errors = np.random.binomial(\n",
        "    n=1,\n",
        "    p=np.where(fault_domains == \"silicon\", 0.25, 0.003),\n",
        "    size=n_samples\n",
        ").astype(int)\n",
        "\n",
        "# Node age and recovery history give temporal context (older nodes fail more often)\n",
        "node_age_days = np.random.exponential(scale=180, size=n_samples).astype(int)\n",
        "prior_recovery_failures = np.random.poisson(\n",
        "    lam=np.where(\n",
        "        fault_domains == \"healthy\", 0.05,\n",
        "        np.where(\n",
        "            fault_domains == \"software\", 0.2,\n",
        "            np.where(\n",
        "                fault_domains == \"signal\", 0.4,\n",
        "                np.where(fault_domains == \"thermal\", 0.5, 1.2)\n",
        "            )\n",
        "        )\n",
        "    ),\n",
        "    size=n_samples\n",
        ")\n",
        "\n",
        "# Assemble the raw dataset (observables only)\n",
        "df_raw = pd.DataFrame({\n",
        "    \"temp_c\": temp_c,\n",
        "    \"fan_rpm\": fan_rpm.astype(int),\n",
        "    \"voltage\": voltage,\n",
        "    \"error_count_24h\": error_count_24h,\n",
        "    \"pcie_width\": pcie_width,\n",
        "    \"pcie_gen\": pcie_gen,\n",
        "    \"retimer_errors\": retimer_errors,\n",
        "    \"gpu_model\": gpu_model,\n",
        "    \"xid_code\": xid_code,\n",
        "    \"is_active_cooling\": is_active_cooling.astype(int),\n",
        "    \"unfixable_ecc_errors\": unfixable_ecc_errors,\n",
        "    \"node_age_days\": node_age_days,\n",
        "    \"prior_recovery_failures\": prior_recovery_failures\n",
        "})\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: Define the N-tier policy labels (what action should be taken)\n",
        "# -----------------------------------------------------------------------------\n",
        "# Labels represent the \"recommended recovery tier\":\n",
        "#   0: No Action (healthy)\n",
        "#   1: Reboot / power-cycle (software / recoverable)\n",
        "#   2: Reseat / component fix (physical / signal integrity)\n",
        "#   3: RMA (hard silicon failure)\n",
        "# =============================================================================\n",
        "def recommend_repair_action(row):\n",
        "    # -------- Tier 3: RMA (hard failure signatures) --------\n",
        "    if row[\"unfixable_ecc_errors\"] > 0 or row[\"error_count_24h\"] > 6:\n",
        "        return 3\n",
        "    if row[\"is_active_cooling\"] == 1 and row[\"fan_rpm\"] < 500 and row[\"temp_c\"] > 85:\n",
        "        return 3\n",
        "    if row[\"xid_code\"] == \"XID_79\" and row[\"pcie_width\"] <= 1:\n",
        "        return 3\n",
        "\n",
        "    # -------- Tier 2: Physical intervention --------\n",
        "    if row[\"is_active_cooling\"] == 0 and row[\"fan_rpm\"] < 500:\n",
        "        return 2\n",
        "    if row[\"pcie_width\"] < 16:\n",
        "        return 2\n",
        "    if row[\"retimer_errors\"] > 6:\n",
        "        return 2\n",
        "    if row[\"xid_code\"] == \"XID_79\" and row[\"pcie_width\"] > 1:\n",
        "        return 2\n",
        "\n",
        "    # -------- Tier 1: Recoverable / software/firmware --------\n",
        "    if row[\"temp_c\"] > 92 and row[\"fan_rpm\"] >= 500:\n",
        "        return 1\n",
        "    if row[\"xid_code\"] in [\"XID_43\", \"XID_31\", \"XID_61\"]:\n",
        "        return 1\n",
        "\n",
        "    # -------- Tier 0: Healthy --------\n",
        "    return 0\n",
        "\n",
        "# Apply the policy function to produce labels\n",
        "df_raw[\"action_label\"] = df_raw.apply(recommend_repair_action, axis=1)\n",
        "\n",
        "# Inject label noise to simulate real-world ambiguity (missing logs, operator variance, etc.)\n",
        "noise_rate = 0.03\n",
        "flip_mask = np.random.rand(len(df_raw)) < noise_rate\n",
        "df_raw.loc[flip_mask, \"action_label\"] = np.random.choice(\n",
        "    [0, 1, 2, 3],\n",
        "    size=flip_mask.sum(),\n",
        "    p=[0.7, 0.15, 0.12, 0.03]\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: Feature extraction (engineered features derived from raw observables)\n",
        "# -----------------------------------------------------------------------------\n",
        "# These mimic high-dimensional feature engineering used in production systems.\n",
        "# =============================================================================\n",
        "def add_extracted_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Add derived / engineered features to strengthen separability between tiers.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - log transforms stabilize heavy-tailed counters (retimer/errors/history)\n",
        "    - composite scores represent domain-specific risk signals\n",
        "    - boolean flags allow trees to capture crisp decision boundaries\n",
        "    \"\"\"\n",
        "    d = df.copy()\n",
        "    eps = 1e-6  # protect divisions\n",
        "\n",
        "    # --- Log transforms for count-like features (reduce skew) ---\n",
        "    d[\"log_retimer_errors\"] = np.log1p(d[\"retimer_errors\"])\n",
        "    d[\"log_error_count_24h\"] = np.log1p(d[\"error_count_24h\"])\n",
        "    d[\"log_prior_recovery_failures\"] = np.log1p(d[\"prior_recovery_failures\"])\n",
        "    d[\"log_node_age_days\"] = np.log1p(d[\"node_age_days\"])\n",
        "\n",
        "    # --- Thermal / cooling features ---\n",
        "    d[\"thermal_headroom\"] = 110 - d[\"temp_c\"]                     # distance from critical temp\n",
        "    d[\"thermal_flag\"] = (d[\"temp_c\"] > 90).astype(int)            # simple hot indicator\n",
        "    d[\"fan_efficiency\"] = d[\"fan_rpm\"] / (d[\"temp_c\"] + eps)      # rpm per degree\n",
        "    d[\"cooling_mismatch\"] = (\n",
        "        (d[\"is_active_cooling\"] == 1) & (d[\"temp_c\"] > 90) & (d[\"fan_rpm\"] < 1200)\n",
        "    ).astype(int)\n",
        "\n",
        "    # --- Power features ---\n",
        "    d[\"voltage_droop\"] = 1.20 - d[\"voltage\"]                      # droop relative to nominal\n",
        "    d[\"droop_severity\"] = np.maximum(0.0, 1.18 - d[\"voltage\"])    # focus on “bad” droop region\n",
        "    d[\"thermal_power_coupling\"] = d[\"temp_c\"] * d[\"voltage_droop\"]# joint stress signal\n",
        "\n",
        "    # --- Interconnect / signal integrity features ---\n",
        "    d[\"pcie_bw_score\"] = d[\"pcie_width\"] * d[\"pcie_gen\"]          # crude bandwidth proxy\n",
        "    d[\"pcie_degraded\"] = ((d[\"pcie_width\"] < 16) | (d[\"pcie_gen\"] < 5)).astype(int)\n",
        "    d[\"signal_integrity_score\"] = d[\"log_retimer_errors\"] + 2.0 * d[\"pcie_degraded\"]\n",
        "\n",
        "    # --- Silicon risk features ---\n",
        "    d[\"error_density\"] = d[\"error_count_24h\"] / (d[\"node_age_days\"] + 1.0)\n",
        "    d[\"ecc_present\"] = d[\"unfixable_ecc_errors\"].astype(int)\n",
        "    d[\"silicon_risk_score\"] = (\n",
        "        3.0 * d[\"ecc_present\"]\n",
        "        + d[\"log_error_count_24h\"]\n",
        "        + 0.7 * np.maximum(0.0, d[\"voltage_droop\"])\n",
        "        + 0.3 * d[\"log_prior_recovery_failures\"]\n",
        "    )\n",
        "\n",
        "    # --- XID one-hot style indicators (tree-friendly) ---\n",
        "    d[\"xid_is_none\"] = (d[\"xid_code\"] == \"NONE\").astype(int)\n",
        "    d[\"xid_is_bus\"] = (d[\"xid_code\"] == \"XID_79\").astype(int)\n",
        "    d[\"xid_is_hang\"] = d[\"xid_code\"].isin([\"XID_31\", \"XID_43\"]).astype(int)\n",
        "    d[\"xid_is_reset\"] = (d[\"xid_code\"] == \"XID_61\").astype(int)\n",
        "\n",
        "    # --- History-based risk / pressure ---\n",
        "    d[\"repeat_failure_flag\"] = (d[\"prior_recovery_failures\"] >= 2).astype(int)\n",
        "    d[\"recovery_pressure\"] = d[\"prior_recovery_failures\"] / (d[\"node_age_days\"] + 7.0)\n",
        "\n",
        "    return d\n",
        "\n",
        "df_full = add_extracted_features(df_raw)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: Train/Val/Test split (stratified to preserve class proportions)\n",
        "# =============================================================================\n",
        "target_names = [\"No Action\", \"Reboot\", \"Reseat\", \"RMA\"]\n",
        "y = df_raw[\"action_label\"]\n",
        "\n",
        "# Create stable index splits so we can compare raw vs engineered features fairly\n",
        "train_idx, temp_idx = train_test_split(\n",
        "    df_raw.index,\n",
        "    test_size=0.30,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "val_idx, test_idx = train_test_split(\n",
        "    temp_idx,\n",
        "    test_size=0.50,\n",
        "    random_state=42,\n",
        "    stratify=y.loc[temp_idx]\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: Training + evaluation helper\n",
        "# -----------------------------------------------------------------------------\n",
        "# This function trains CatBoost and reports:\n",
        "# - Balanced accuracy (good for imbalance)\n",
        "# - Macro F1 (treats classes equally)\n",
        "# - Weighted F1 (accounts for class frequency)\n",
        "# Plus confusion matrix and top feature importances.\n",
        "# =============================================================================\n",
        "def train_and_eval(X_df: pd.DataFrame, y_series: pd.Series, title: str):\n",
        "    # Split by index to ensure identical train/val/test across experiments\n",
        "    X_train = X_df.loc[train_idx]\n",
        "    X_val   = X_df.loc[val_idx]\n",
        "    X_test  = X_df.loc[test_idx]\n",
        "    y_train = y_series.loc[train_idx]\n",
        "    y_val   = y_series.loc[val_idx]\n",
        "    y_test  = y_series.loc[test_idx]\n",
        "\n",
        "    # Identify categorical columns for CatBoost (it handles encoding internally)\n",
        "    cat_cols = [c for c in [\"gpu_model\", \"xid_code\"] if c in X_df.columns]\n",
        "    cat_features = [X_df.columns.get_loc(c) for c in cat_cols]  # CatBoost expects indices\n",
        "\n",
        "    # Class weights to compensate imbalance (esp. rare \"RMA\")\n",
        "    counts = y_train.value_counts().sort_index()\n",
        "    class_weights = (counts.sum() / (len(counts) * counts)).tolist()\n",
        "\n",
        "    # CatBoost configuration tuned for multiclass + imbalance\n",
        "    model = CatBoostClassifier(\n",
        "        loss_function=\"MultiClass\",\n",
        "        eval_metric=\"TotalF1:average=Macro\",  # prefer macro-F1 over raw accuracy\n",
        "        iterations=400,\n",
        "        learning_rate=0.08,\n",
        "        depth=7,\n",
        "        l2_leaf_reg=6,\n",
        "        random_seed=42,\n",
        "        class_weights=class_weights,\n",
        "        od_type=\"Iter\",   # early stopping\n",
        "        od_wait=50,\n",
        "        verbose=100\n",
        "    )\n",
        "\n",
        "    # Train with a validation set and keep best iteration\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        cat_features=cat_features,\n",
        "        eval_set=(X_val, y_val),\n",
        "        use_best_model=True\n",
        "    )\n",
        "\n",
        "    # CatBoost predict() returns shape (n,1); convert to flat int array\n",
        "    pred = model.predict(X_test).astype(int).reshape(-1)\n",
        "\n",
        "    # Core metrics for paper reporting\n",
        "    bal_acc = balanced_accuracy_score(y_test, pred)\n",
        "    f1_macro = f1_score(y_test, pred, average=\"macro\")\n",
        "    f1_weighted = f1_score(y_test, pred, average=\"weighted\")\n",
        "\n",
        "    # ---- Print metrics + full per-class report ----\n",
        "    print(\"=\" * 90)\n",
        "    print(title)\n",
        "    print(\"Balanced Accuracy:\", bal_acc)\n",
        "    print(\"F1 Macro:\", f1_macro)\n",
        "    print(\"F1 Weighted:\", f1_weighted)\n",
        "    print()\n",
        "    print(classification_report(y_test, pred, target_names=target_names))\n",
        "\n",
        "    # ---- Confusion matrix visualization ----\n",
        "    cm = confusion_matrix(y_test, pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm)\n",
        "    plt.xticks(range(4), target_names, rotation=20)\n",
        "    plt.yticks(range(4), target_names)\n",
        "    plt.title(f\"Confusion Matrix (Test) - {title}\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.colorbar()\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ---- Feature importance (top 12) ----\n",
        "    imp = (\n",
        "        pd.Series(model.get_feature_importance(), index=X_df.columns)\n",
        "        .sort_values(ascending=False)\n",
        "        .head(12)\n",
        "    )\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.barh(imp.index[::-1], imp.values[::-1])\n",
        "    plt.title(f\"Top Feature Importances (CatBoost) - {title}\")\n",
        "    plt.xlabel(\"Importance\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return {\"title\": title, \"balanced_accuracy\": bal_acc, \"f1_macro\": f1_macro, \"f1_weighted\": f1_weighted}\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: Run two experiments\n",
        "#   (A) Raw observables only\n",
        "#   (B) Raw + engineered features\n",
        "# =============================================================================\n",
        "X_raw = df_raw.drop(columns=[\"action_label\"])\n",
        "res_raw = train_and_eval(X_raw, y, \"Raw Features Only\")\n",
        "\n",
        "X_full = df_full.drop(columns=[\"action_label\"])\n",
        "res_full = train_and_eval(X_full, y, \"Raw + Extracted Features\")\n",
        "\n",
        "# Summarize results for quick comparison (useful for paper tables)\n",
        "summary = pd.DataFrame([res_raw, res_full])\n",
        "summary\n"
      ]
    }
  ]
}